==========================================================
Job Started on n-62-20-15
Job ID: 24750496
Working Directory: /zhome/44/a/187127/school/Water-level-forecasting-new-project
Requested Cores: 4
Allocated Hosts: n-62-20-15 n-62-20-15 n-62-20-15 n-62-20-15
Queue: gpuv100
Start Time: Tue Apr 22 12:05:04 CEST 2025
==========================================================
Loading required modules...
Modules loaded:
Activating Conda environment 'forecasting'...
Conda environment: forecastinghpc
Python path: /zhome/44/a/187127/anaconda3/envs/forecastinghpc/bin/python
Working directory set to: /zhome/44/a/187127/school/Water-level-forecasting-new-project
Running automl.py...
2025-04-22 12:05:09.054768
sucess
                level  month  year  dayofyear  weekofyear
time                                                     
2014-06-20  11.437010      6  2014        171          25
2014-06-21  11.439094      6  2014        172          25
2014-06-22  11.435438      6  2014        173          25
2014-06-23  11.428292      6  2014        174          26
2014-06-24  11.427969      6  2014        175          26
ERROR: Python script automl.py failed with exit status 1

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 24750496: <AutoML_WaterLevel> in cluster <dcc> Exited

Job <AutoML_WaterLevel> was submitted from host <hpclogin1> by user <s224296> in cluster <dcc> at Tue Apr 22 12:05:01 2025
Job was executed on host(s) <4*n-62-20-15>, in queue <gpuv100>, as user <s224296> in cluster <dcc> at Tue Apr 22 12:05:01 2025
</zhome/44/a/187127> was used as the home directory.
</zhome/44/a/187127/school/Water-level-forecasting-new-project> was used as the working directory.
Started at Tue Apr 22 12:05:01 2025
Terminated at Tue Apr 22 12:05:09 2025
Results reported at Tue Apr 22 12:05:09 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
# LSF Batch Job Script for running automl.py

### General LSF options ###

# -- Specify the queue --
# Use a GPU queue appropriate for your models (e.g., gpuv100 or gpua100)
# Remember A100 requires code compiled with CUDA >= 11.0
#BSUB -q gpuv100

# -- Set the job Name --
#BSUB -J AutoML_WaterLevel

# -- Ask for number of cores (CPU slots) --
# Adjust based on data loading/preprocessing needs. 8 is a reasonable start.
#BSUB -n 4

# -- Request GPU resources --
# Request 1 GPU in exclusive process mode.
#BSUB -gpu "num=1:mode=exclusive_process"

# -- Specify that all cores/GPU must be on the same host/node --
#BSUB -R "span[hosts=1]"

# -- Specify memory requested PER CORE/SLOT --
# Example: 8GB RAM per core (total 64GB). ADJUST BASED ON YOUR NEEDS!
#BSUB -R "rusage[mem=8GB]"

# -- Specify memory limit PER CORE/SLOT (Job killed if exceeded) --
# Example: 10GB per core (total 80GB limit). ADJUST BASED ON YOUR NEEDS!
#BSUB -M 9GB

# -- Set walltime limit: hh:mm --
# Max 24:00 for GPU queues. START SHORT (e.g., 1:00) FOR TESTING!
# Adjust based on expected runtime for the full job.
#BSUB -W 10:00

# -- Specify output and error files (%J expands to Job ID) --
# We'll create the 'logs' directory below.
#BSUB -o logs/automl_%J.out
#BSUB -e logs/automl_%J.err

# -- Email notifications (Optional) --
# Uncomment and set your DTU email if desired
##BSUB -u s224296@dtu.dk  # Use your actual email
# Send email on job start (-B) and job end/failure (-N)
##BSUB -B
##BSUB -N

### End of LSF options ###

(... more ...)
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   4.14 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     32768.00 MB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   8 sec.
    Turnaround time :                            8 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/automl_24750496.err> for stderr output of this job.

