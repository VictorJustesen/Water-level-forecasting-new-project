==========================================================
Job Started on n-62-20-16
Job ID: 24639216
Working Directory: /zhome/44/a/187127/school/Water-level-forecasting-new-project
Requested Cores: 4
Allocated Hosts: n-62-20-16 n-62-20-16 n-62-20-16 n-62-20-16
Queue: gpuv100
Start Time: Fri Apr 11 05:49:38 CEST 2025
==========================================================
Loading required modules...
Modules loaded:
Activating Conda environment 'forecasting'...
Conda environment: forecastinghpc
Python path: /zhome/44/a/187127/anaconda3/envs/forecastinghpc/bin/python
Working directory set to: /zhome/44/a/187127/school/Water-level-forecasting-new-project
Running automl.py...
2025-04-11 05:49:54.331905
sucess
                level       temp  bright_sunshine  ...  year  dayofyear  weekofyear
time                                               ...                             
2014-08-20  11.397573  14.012500              9.5  ...  2014        232          34
2014-08-21  11.390281  13.754167              6.1  ...  2014        233          34
2014-08-22  11.387896  13.637500              8.1  ...  2014        234          34
2014-08-23  11.395344  13.666667              3.2  ...  2014        235          34
2014-08-24  11.395281  13.412500              6.7  ...  2014        236          34

[5 rows x 10 columns]
running models:  ['linear_model', 'fnn_model', 'rnn_model', 'cnn_model', 'rnnlstm_model', 'baseline_model']
error metric:  mse
Index(['level', 'temp', 'bright_sunshine', 'mean_relative_hum', 'acc_precip',
       'mean_temp', 'month', 'year', 'dayofyear', 'weekofyear', 'lag_7d_avg',
       'lag_30d_avg', 'lag_7d', 'lag_365d'],
      dtype='object')
feature selection

Performing feature selection for linear_model
Tested feature 'temp': Mean mse = 0.01630053552250954
Tested feature 'bright_sunshine': Mean mse = 0.021663375842823563
Tested feature 'mean_relative_hum': Mean mse = 0.020909833609048373
Tested feature 'acc_precip': Mean mse = 0.015924815376452035
Tested feature 'mean_temp': Mean mse = 0.014958930283347948
Tested feature 'month': Mean mse = 0.011717520783727921
Tested feature 'year': Mean mse = 0.00635491628364625
Tested feature 'dayofyear': Mean mse = 0.01176367517042929
Tested feature 'weekofyear': Mean mse = 0.01219134800784934
Tested feature 'lag_7d_avg': Mean mse = 0.0011744317366274143
Tested feature 'lag_30d_avg': Mean mse = 0.0041228004566865855
Tested feature 'lag_7d': Mean mse = 0.0011744317366274143
Tested feature 'lag_365d': Mean mse = 0.013424712391679066
Selected feature 'lag_7d_avg' with improvement to mse = 0.0011744317366274143
Tested feature 'temp': Mean mse = 0.00214093633953762
Tested feature 'bright_sunshine': Mean mse = 0.0023149392863156372
Tested feature 'mean_relative_hum': Mean mse = 0.0021497106408476267
Tested feature 'acc_precip': Mean mse = 0.001048972915833377
Tested feature 'mean_temp': Mean mse = 0.0015787214508851035
Tested feature 'month': Mean mse = 0.0011409158286191678
Tested feature 'year': Mean mse = 0.0007004833007229836
Tested feature 'dayofyear': Mean mse = 0.0011460272763646367
Tested feature 'weekofyear': Mean mse = 0.0011827659594253058
Tested feature 'lag_30d_avg': Mean mse = 0.0008187170348850374
Tested feature 'lag_7d': Mean mse = 0.0011744317366274056
Tested feature 'lag_365d': Mean mse = 0.0011108828954407362
Selected feature 'year' with improvement to mse = 0.0007004833007229836
Tested feature 'temp': Mean mse = 0.0012280022579218204
Tested feature 'bright_sunshine': Mean mse = 0.0013989165425532983
Tested feature 'mean_relative_hum': Mean mse = 0.0013385649621425115
Tested feature 'acc_precip': Mean mse = 0.0007414837391304817
Tested feature 'mean_temp': Mean mse = 0.000820674041486789
Tested feature 'month': Mean mse = 0.0006541385011500457
Tested feature 'dayofyear': Mean mse = 0.0006583444994340892
Tested feature 'weekofyear': Mean mse = 0.0006734216117746774
Tested feature 'lag_30d_avg': Mean mse = 0.0006121489238997367
Tested feature 'lag_7d': Mean mse = 0.0007004833007229893
Tested feature 'lag_365d': Mean mse = 0.0006431991988332291
Selected feature 'lag_30d_avg' with improvement to mse = 0.0006121489238997367
Tested feature 'temp': Mean mse = 0.0010164670640184928
Tested feature 'bright_sunshine': Mean mse = 0.0010721712561841898
Tested feature 'mean_relative_hum': Mean mse = 0.0010554802591748805
Tested feature 'acc_precip': Mean mse = 0.000661278977481931
Tested feature 'mean_temp': Mean mse = 0.0006655399340808943
Tested feature 'month': Mean mse = 0.000616440381073745
Tested feature 'dayofyear': Mean mse = 0.0006169677076964987
Tested feature 'weekofyear': Mean mse = 0.000623540239937535
Tested feature 'lag_7d': Mean mse = 0.0006121489238996749
Tested feature 'lag_365d': Mean mse = 0.0006231734123991745
Selected feature 'lag_7d' with improvement to mse = 0.0006121489238996749
Tested feature 'temp': Mean mse = 0.0010164670640184497
Tested feature 'bright_sunshine': Mean mse = 0.0010721712561841785
Tested feature 'mean_relative_hum': Mean mse = 0.0010554802591748308
Tested feature 'acc_precip': Mean mse = 0.0006612789774819232
Tested feature 'mean_temp': Mean mse = 0.0006655399340809099
Tested feature 'month': Mean mse = 0.0006164403810737304
Tested feature 'dayofyear': Mean mse = 0.0006169677076964534
Tested feature 'weekofyear': Mean mse = 0.0006235402399375194
Tested feature 'lag_365d': Mean mse = 0.0006231734123991642
No further improvement, stopping feature selection.
Selected features for 'linear_model': ['lag_7d_avg', 'year', 'lag_30d_avg', 'lag_7d']

Performing feature selection for fnn_model
Tested feature 'temp': Mean mse = 0.016376658655005177
Tested feature 'bright_sunshine': Mean mse = 0.0229741904738523
Tested feature 'mean_relative_hum': Mean mse = 0.02239233876783686
Tested feature 'acc_precip': Mean mse = 0.022267270107654804
Tested feature 'mean_temp': Mean mse = 0.014770859065464622
Tested feature 'month': Mean mse = 0.020552249018423153
Tested feature 'year': Mean mse = 0.2099610253939889
Tested feature 'dayofyear': Mean mse = 0.06084276657755651
Tested feature 'weekofyear': Mean mse = 0.019446453448398095
Tested feature 'lag_7d_avg': Mean mse = 0.0013204129636287952
Tested feature 'lag_30d_avg': Mean mse = 0.0013078174273531474
Tested feature 'lag_7d': Mean mse = 0.001020266982490786
Tested feature 'lag_365d': Mean mse = 0.008160747571638446
Selected feature 'lag_7d' with improvement to mse = 0.001020266982490786
Tested feature 'temp': Mean mse = 0.0009069943601508212
Tested feature 'bright_sunshine': Mean mse = 0.0012496420958945016
Tested feature 'mean_relative_hum': Mean mse = 0.003893323789332788
Tested feature 'acc_precip': Mean mse = 0.0006659386691591707
Tested feature 'mean_temp': Mean mse = 0.001997654158023739
Tested feature 'month': Mean mse = 0.0016276981640012944
Tested feature 'year': Mean mse = 0.38679317201279606
Tested feature 'dayofyear': Mean mse = 0.06780226711291126
Tested feature 'weekofyear': Mean mse = 0.008692579915297365
Tested feature 'lag_7d_avg': Mean mse = 0.0011551895575042533
Tested feature 'lag_30d_avg': Mean mse = 0.0018808148058138286
Tested feature 'lag_365d': Mean mse = 0.0029970309817745865
Selected feature 'acc_precip' with improvement to mse = 0.0006659386691591707
Tested feature 'temp': Mean mse = 0.0028980726295394234
Tested feature 'bright_sunshine': Mean mse = 0.001256885593986723
Tested feature 'mean_relative_hum': Mean mse = 0.01590176234942851
Tested feature 'mean_temp': Mean mse = 0.0023976996830112
Tested feature 'month': Mean mse = 0.0013826894830434556
Tested feature 'year': Mean mse = 0.17492516006314576
Tested feature 'dayofyear': Mean mse = 0.05310671461029681
Tested feature 'weekofyear': Mean mse = 0.011947828812663088
Tested feature 'lag_7d_avg': Mean mse = 0.0029322870796027974
Tested feature 'lag_30d_avg': Mean mse = 0.002117413014781573
Tested feature 'lag_365d': Mean mse = 0.0015129239153172758
No further improvement, stopping feature selection.
Selected features for 'fnn_model': ['lag_7d', 'acc_precip']

Performing feature selection for rnn_model
Tested feature 'temp': Mean mse = 0.01525934973422422
Tested feature 'bright_sunshine': Mean mse = 0.036326698493122096
Tested feature 'mean_relative_hum': Mean mse = 0.19135821681082552
Tested feature 'acc_precip': Mean mse = 0.018362913361987962
Tested feature 'mean_temp': Mean mse = 0.017300707190482455
Tested feature 'month': Mean mse = 0.013660372308192175
Tested feature 'year': Mean mse = 0.05327546472965359
Tested feature 'dayofyear': Mean mse = 0.012019203599383993
Tested feature 'weekofyear': Mean mse = 0.014538648604101265
Tested feature 'lag_7d_avg': Mean mse = 0.0006760849033686183
Tested feature 'lag_30d_avg': Mean mse = 0.0015192668739623274
Tested feature 'lag_7d': Mean mse = 0.000721400878973769
Tested feature 'lag_365d': Mean mse = 0.007524398463688828
Selected feature 'lag_7d_avg' with improvement to mse = 0.0006760849033686183
Tested feature 'temp': Mean mse = 0.0023703395140963865
Tested feature 'bright_sunshine': Mean mse = 0.0012411174507559566
Tested feature 'mean_relative_hum': Mean mse = 0.0035284530962688826
Tested feature 'acc_precip': Mean mse = 0.0009316959899782744
Tested feature 'mean_temp': Mean mse = 0.0010473867999770522
Tested feature 'month': Mean mse = 0.0008992324510652469
Tested feature 'year': Mean mse = 0.09183186628705561
Tested feature 'dayofyear': Mean mse = 0.012394819460811656
Tested feature 'weekofyear': Mean mse = 0.003462732630235419
Tested feature 'lag_30d_avg': Mean mse = 0.00128988790878038
Tested feature 'lag_7d': Mean mse = 0.0010659799236753475
Tested feature 'lag_365d': Mean mse = 0.0017519914704835395
No further improvement, stopping feature selection.
Selected features for 'rnn_model': ['lag_7d_avg']

Performing feature selection for cnn_model
Tested feature 'temp': Mean mse = 0.02378216825080371
Tested feature 'bright_sunshine': Mean mse = 0.020111328937016434
Tested feature 'mean_relative_hum': Mean mse = 0.05079021339282754
Tested feature 'acc_precip': Mean mse = 0.01689710901073071
Tested feature 'mean_temp': Mean mse = 0.0257572482921008
Tested feature 'month': Mean mse = 0.019071646407524772
Tested feature 'year': Mean mse = 0.48192977575492657
Tested feature 'dayofyear': Mean mse = 0.09150222974353266
Tested feature 'weekofyear': Mean mse = 0.04980608866977175
Tested feature 'lag_7d_avg': Mean mse = 0.0011598148706376142
Tested feature 'lag_30d_avg': Mean mse = 0.002184829056592308
Tested feature 'lag_7d': Mean mse = 0.000932661320498297
Tested feature 'lag_365d': Mean mse = 0.008438111967073586
Selected feature 'lag_7d' with improvement to mse = 0.000932661320498297
Tested feature 'temp': Mean mse = 0.003923037530839378
Tested feature 'bright_sunshine': Mean mse = 0.0015124628542166174
Tested feature 'mean_relative_hum': Mean mse = 0.005733671694822974
Tested feature 'acc_precip': Mean mse = 0.001396637542720686
Tested feature 'mean_temp': Mean mse = 0.003170338490493828
Tested feature 'month': Mean mse = 0.0013080986853099149
Tested feature 'year': Mean mse = 0.23797314350415438
Tested feature 'dayofyear': Mean mse = 0.2597908819950587
Tested feature 'weekofyear': Mean mse = 0.00781419321849574
Tested feature 'lag_7d_avg': Mean mse = 0.0010791900540745756
Tested feature 'lag_30d_avg': Mean mse = 0.0011679768944869173
Tested feature 'lag_365d': Mean mse = 0.0022732227246385866
No further improvement, stopping feature selection.
Selected features for 'cnn_model': ['lag_7d']

Performing feature selection for rnnlstm_model
Tested feature 'temp': Mean mse = 0.03229584047894617
Tested feature 'bright_sunshine': Mean mse = 0.04534686526464434
Tested feature 'mean_relative_hum': Mean mse = 0.022722210720163935
Tested feature 'acc_precip': Mean mse = 0.023622064520437556
Tested feature 'mean_temp': Mean mse = 0.01878643974098046
Tested feature 'month': Mean mse = 0.016692896608594212
Tested feature 'year': Mean mse = 0.040493512178271754
Tested feature 'dayofyear': Mean mse = 0.012963983042162553
Tested feature 'weekofyear': Mean mse = 0.01732017685454177
Tested feature 'lag_7d_avg': Mean mse = 0.004320703346820711
Tested feature 'lag_30d_avg': Mean mse = 0.004488863669370022
Tested feature 'lag_7d': Mean mse = 0.002672619383885
Tested feature 'lag_365d': Mean mse = 0.008445028918795141
Selected feature 'lag_7d' with improvement to mse = 0.002672619383885
Tested feature 'temp': Mean mse = 0.004838348952788338
Tested feature 'bright_sunshine': Mean mse = 0.002125943985963895
Tested feature 'mean_relative_hum': Mean mse = 0.003688374335992531
Tested feature 'acc_precip': Mean mse = 0.0034714009145098146
Tested feature 'mean_temp': Mean mse = 0.00217392785382453
Tested feature 'month': Mean mse = 0.0016091820712775963
Tested feature 'year': Mean mse = 0.022076266170951337
Tested feature 'dayofyear': Mean mse = 0.009247798097575626
Tested feature 'weekofyear': Mean mse = 0.002247174609903527
Tested feature 'lag_7d_avg': Mean mse = 0.0034524769865750247
Tested feature 'lag_30d_avg': Mean mse = 0.0029803509884717867
Tested feature 'lag_365d': Mean mse = 0.0017844078591047225
Selected feature 'month' with improvement to mse = 0.0016091820712775963
Tested feature 'temp': Mean mse = 0.003846465456612178
Tested feature 'bright_sunshine': Mean mse = 0.0005479769251993236
Tested feature 'mean_relative_hum': Mean mse = 0.0037215054775990588
Tested feature 'acc_precip': Mean mse = 0.0015294250321809873
Tested feature 'mean_temp': Mean mse = 0.0005674263103321859
Tested feature 'year': Mean mse = 0.02218994275902169
Tested feature 'dayofyear': Mean mse = 0.006095890870170052
Tested feature 'weekofyear': Mean mse = 0.0023471616788764684
Tested feature 'lag_7d_avg': Mean mse = 0.0012011857656049124
Tested feature 'lag_30d_avg': Mean mse = 0.0014279342387327255
Tested feature 'lag_365d': Mean mse = 0.0023617086529377014
Selected feature 'bright_sunshine' with improvement to mse = 0.0005479769251993236
Tested feature 'temp': Mean mse = 0.0026920753264428783
Tested feature 'mean_relative_hum': Mean mse = 0.0030605931009893006
Tested feature 'acc_precip': Mean mse = 0.0020690670446541623
Tested feature 'mean_temp': Mean mse = 0.0029433882102280636
Tested feature 'year': Mean mse = 0.017636821955745334
Tested feature 'dayofyear': Mean mse = 0.011609774447363854
Tested feature 'weekofyear': Mean mse = 0.0019986257696347526
Tested feature 'lag_7d_avg': Mean mse = 0.0022040211419094755
Tested feature 'lag_30d_avg': Mean mse = 0.0011211461233091267
Tested feature 'lag_365d': Mean mse = 0.0031315037554420348
No further improvement, stopping feature selection.
Selected features for 'rnnlstm_model': ['lag_7d', 'month', 'bright_sunshine']

Performing feature selection for baseline_model
Univariate model selected. Using 'level' as the only feature for 'baseline_model'.

Starting hyperparameter tuning for 'linear_model'
Optimizing parameter group 'group1' for 'linear_model'
Tested params {'fit_intercept': True}: Mean mse = 0.0006121489238996749
New best params for 'linear_model': {'fit_intercept': True} with Mean mse = 0.0006121489238996749
Tested params {'fit_intercept': False}: Mean mse = 0.0008431926591467105
Best parameters for 'linear_model': {'fit_intercept': True}
Best mean error for 'linear_model': 0.0006121489238996749

Starting hyperparameter tuning for 'fnn_model'
Optimizing parameter group 'group1_structure' for 'fnn_model'
Tested params {'units_layer1': 32, 'units_layer2': 16}: Mean mse = 0.0008094936157712857
New best params for 'fnn_model': {'units_layer1': 32, 'units_layer2': 16} with Mean mse = 0.0008094936157712857
Tested params {'units_layer1': 32, 'units_layer2': 32}: Mean mse = 0.001875078440851249
Tested params {'units_layer1': 32, 'units_layer2': 64}: Mean mse = 0.0015597173898573334
Tested params {'units_layer1': 64, 'units_layer2': 16}: Mean mse = 0.001597864797902743
Tested params {'units_layer1': 64, 'units_layer2': 32}: Mean mse = 0.0008265146506024176
Tested params {'units_layer1': 64, 'units_layer2': 64}: Mean mse = 0.0014941338640669685
Tested params {'units_layer1': 128, 'units_layer2': 16}: Mean mse = 0.0013739337593353627
Tested params {'units_layer1': 128, 'units_layer2': 32}: Mean mse = 0.0018954656713045914
Tested params {'units_layer1': 128, 'units_layer2': 64}: Mean mse = 0.002198193730920373
Optimizing parameter group 'group2_activation' for 'fnn_model'
Tested params {'activation_layer1': 'relu', 'activation_layer2': 'relu'}: Mean mse = 0.0017119862802201205
Tested params {'activation_layer1': 'relu', 'activation_layer2': 'tanh'}: Mean mse = 0.01616153313120104
Tested params {'activation_layer1': 'tanh', 'activation_layer2': 'relu'}: Mean mse = 0.013098517669963372
Tested params {'activation_layer1': 'tanh', 'activation_layer2': 'tanh'}: Mean mse = 0.016752302308996096
Optimizing parameter group 'group3_training' for 'fnn_model'
Tested params {'batch_size': 32, 'epochs': 50, 'optimizer': 'adam'}: Mean mse = 0.0013413072307090215
Tested params {'batch_size': 32, 'epochs': 50, 'optimizer': 'rmsprop'}: Mean mse = 0.008659357407469818
Tested params {'batch_size': 32, 'epochs': 100, 'optimizer': 'adam'}: Mean mse = 0.0012141294750681235
Tested params {'batch_size': 32, 'epochs': 100, 'optimizer': 'rmsprop'}: Mean mse = 0.012821634678866045
Tested params {'batch_size': 64, 'epochs': 50, 'optimizer': 'adam'}: Mean mse = 0.0008232070480235908
Tested params {'batch_size': 64, 'epochs': 50, 'optimizer': 'rmsprop'}: Mean mse = 0.008316845128874355
Tested params {'batch_size': 64, 'epochs': 100, 'optimizer': 'adam'}: Mean mse = 0.0007680146370134183
New best params for 'fnn_model': {'units_layer1': 32, 'units_layer2': 16, 'batch_size': 64, 'epochs': 100, 'optimizer': 'adam'} with Mean mse = 0.0007680146370134183
Tested params {'batch_size': 64, 'epochs': 100, 'optimizer': 'rmsprop'}: Mean mse = 0.00692140369305367
Best parameters for 'fnn_model': {'units_layer1': 32, 'units_layer2': 16, 'batch_size': 64, 'epochs': 100, 'optimizer': 'adam'}
Best mean error for 'fnn_model': 0.0007680146370134183

Starting hyperparameter tuning for 'rnn_model'
Optimizing parameter group 'group1_structure' for 'rnn_model'
Tested params {'units': 32}: Mean mse = 0.0007451776612327003
New best params for 'rnn_model': {'units': 32} with Mean mse = 0.0007451776612327003
Tested params {'units': 50}: Mean mse = 0.0007620638832190592
Tested params {'units': 100}: Mean mse = 0.0011224562203441446
Optimizing parameter group 'group2_activation' for 'rnn_model'
Tested params {'activation': 'relu'}: Mean mse = 0.0007789881207252735
Tested params {'activation': 'tanh'}: Mean mse = 0.01422901102415339
Optimizing parameter group 'group3_training' for 'rnn_model'
Tested params {'batch_size': 32, 'epochs': 50, 'optimizer': 'adam'}: Mean mse = 0.0007303555689094929
New best params for 'rnn_model': {'units': 32, 'batch_size': 32, 'epochs': 50, 'optimizer': 'adam'} with Mean mse = 0.0007303555689094929
Tested params {'batch_size': 32, 'epochs': 50, 'optimizer': 'rmsprop'}: Mean mse = 0.003186408485648952
Tested params {'batch_size': 32, 'epochs': 100, 'optimizer': 'adam'}: Mean mse = 0.0010618735357163498
Tested params {'batch_size': 32, 'epochs': 100, 'optimizer': 'rmsprop'}: Mean mse = 0.0040268958940095426
Tested params {'batch_size': 64, 'epochs': 50, 'optimizer': 'adam'}: Mean mse = 0.0006226614870621077
New best params for 'rnn_model': {'units': 32, 'batch_size': 64, 'epochs': 50, 'optimizer': 'adam'} with Mean mse = 0.0006226614870621077
Tested params {'batch_size': 64, 'epochs': 50, 'optimizer': 'rmsprop'}: Mean mse = 0.0015977600262980693
Tested params {'batch_size': 64, 'epochs': 100, 'optimizer': 'adam'}: Mean mse = 0.0006915650847491681
Tested params {'batch_size': 64, 'epochs': 100, 'optimizer': 'rmsprop'}: Mean mse = 0.0011465635768167274
Best parameters for 'rnn_model': {'units': 32, 'batch_size': 64, 'epochs': 50, 'optimizer': 'adam'}
Best mean error for 'rnn_model': 0.0006226614870621077

Starting hyperparameter tuning for 'cnn_model'
Optimizing parameter group 'group1_cnn_structure' for 'cnn_model'
Tested params {'filters': 32, 'kernel_size': 2, 'pool_size': 2}: Mean mse = 0.0014740056301392208
New best params for 'cnn_model': {'filters': 32, 'kernel_size': 2, 'pool_size': 2} with Mean mse = 0.0014740056301392208
Tested params {'filters': 32, 'kernel_size': 3, 'pool_size': 2}: Mean mse = 0.00116239287314119
New best params for 'cnn_model': {'filters': 32, 'kernel_size': 3, 'pool_size': 2} with Mean mse = 0.00116239287314119
Tested params {'filters': 32, 'kernel_size': 5, 'pool_size': 2}: Mean mse = 0.0007556012527781959
New best params for 'cnn_model': {'filters': 32, 'kernel_size': 5, 'pool_size': 2} with Mean mse = 0.0007556012527781959
Tested params {'filters': 64, 'kernel_size': 2, 'pool_size': 2}: Mean mse = 0.0016586955480966507
Tested params {'filters': 64, 'kernel_size': 3, 'pool_size': 2}: Mean mse = 0.0007368278143704344
New best params for 'cnn_model': {'filters': 64, 'kernel_size': 3, 'pool_size': 2} with Mean mse = 0.0007368278143704344
Tested params {'filters': 64, 'kernel_size': 5, 'pool_size': 2}: Mean mse = 0.0009755011765711002
Tested params {'filters': 128, 'kernel_size': 2, 'pool_size': 2}: Mean mse = 0.001150610507833783
Tested params {'filters': 128, 'kernel_size': 3, 'pool_size': 2}: Mean mse = 0.0003627950140755399
New best params for 'cnn_model': {'filters': 128, 'kernel_size': 3, 'pool_size': 2} with Mean mse = 0.0003627950140755399
Tested params {'filters': 128, 'kernel_size': 5, 'pool_size': 2}: Mean mse = 0.0005845079529683837
Optimizing parameter group 'group2_dense_structure' for 'cnn_model'
Tested params {'dense_units': 32}: Mean mse = 0.0021664083864367948
Tested params {'dense_units': 50}: Mean mse = 0.0011414489971418068
Tested params {'dense_units': 100}: Mean mse = 0.0016064325222985918
Optimizing parameter group 'group3_activation' for 'cnn_model'
Tested params {'activation': 'relu'}: Mean mse = 0.0008392498464946489
Tested params {'activation': 'tanh'}: Mean mse = 0.015725295742109978
Optimizing parameter group 'group4_training' for 'cnn_model'
Tested params {'batch_size': 32, 'epochs': 50, 'optimizer': 'adam'}: Mean mse = 0.0008555372191632108
Tested params {'batch_size': 32, 'epochs': 50, 'optimizer': 'rmsprop'}: Mean mse = 0.03702405391224066
Tested params {'batch_size': 32, 'epochs': 100, 'optimizer': 'adam'}: Mean mse = 0.0016851472275724445
Tested params {'batch_size': 32, 'epochs': 100, 'optimizer': 'rmsprop'}: Mean mse = 0.017652238471392433
Tested params {'batch_size': 64, 'epochs': 50, 'optimizer': 'adam'}: Mean mse = 0.0007821446273391245
Tested params {'batch_size': 64, 'epochs': 50, 'optimizer': 'rmsprop'}: Mean mse = 0.030335464526625704
Tested params {'batch_size': 64, 'epochs': 100, 'optimizer': 'adam'}: Mean mse = 0.0008173242410998985
Tested params {'batch_size': 64, 'epochs': 100, 'optimizer': 'rmsprop'}: Mean mse = 0.0197449670171781
Best parameters for 'cnn_model': {'filters': 128, 'kernel_size': 3, 'pool_size': 2}
Best mean error for 'cnn_model': 0.0003627950140755399

Starting hyperparameter tuning for 'rnnlstm_model'
Optimizing parameter group 'group1_structure' for 'rnnlstm_model'
Tested params {'units': 32}: Mean mse = 0.0015679999063688992
New best params for 'rnnlstm_model': {'units': 32} with Mean mse = 0.0015679999063688992

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 24639216: <AutoML_WaterLevel> in cluster <dcc> Exited

Job <AutoML_WaterLevel> was submitted from host <hpclogin1> by user <s224296> in cluster <dcc> at Fri Apr 11 05:49:33 2025
Job was executed on host(s) <4*n-62-20-16>, in queue <gpuv100>, as user <s224296> in cluster <dcc> at Fri Apr 11 05:49:33 2025
</zhome/44/a/187127> was used as the home directory.
</zhome/44/a/187127/school/Water-level-forecasting-new-project> was used as the working directory.
Started at Fri Apr 11 05:49:33 2025
Terminated at Fri Apr 11 09:47:18 2025
Results reported at Fri Apr 11 09:47:18 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
# LSF Batch Job Script for running automl.py

### General LSF options ###

# -- Specify the queue --
# Use a GPU queue appropriate for your models (e.g., gpuv100 or gpua100)
# Remember A100 requires code compiled with CUDA >= 11.0
#BSUB -q gpuv100

# -- Set the job Name --
#BSUB -J AutoML_WaterLevel

# -- Ask for number of cores (CPU slots) --
# Adjust based on data loading/preprocessing needs. 8 is a reasonable start.
#BSUB -n 4

# -- Request GPU resources --
# Request 1 GPU in exclusive process mode.
#BSUB -gpu "num=1:mode=exclusive_process"

# -- Specify that all cores/GPU must be on the same host/node --
#BSUB -R "span[hosts=1]"

# -- Specify memory requested PER CORE/SLOT --
# Example: 8GB RAM per core (total 64GB). ADJUST BASED ON YOUR NEEDS!
#BSUB -R "rusage[mem=8GB]"

# -- Specify memory limit PER CORE/SLOT (Job killed if exceeded) --
# Example: 10GB per core (total 80GB limit). ADJUST BASED ON YOUR NEEDS!
#BSUB -M 9GB

# -- Set walltime limit: hh:mm --
# Max 24:00 for GPU queues. START SHORT (e.g., 1:00) FOR TESTING!
# Adjust based on expected runtime for the full job.
#BSUB -W 04:00

# -- Specify output and error files (%J expands to Job ID) --
# We'll create the 'logs' directory below.
#BSUB -o logs/automl_%J.out
#BSUB -e logs/automl_%J.err

# -- Email notifications (Optional) --
# Uncomment and set your DTU email if desired
##BSUB -u s224296@dtu.dk  # Use your actual email
# Send email on job start (-B) and job end/failure (-N)
##BSUB -B
##BSUB -N

### End of LSF options ###

(... more ...)
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   19746.00 sec.
    Max Memory :                                 17593 MB
    Average Memory :                             10271.66 MB
    Total Requested Memory :                     32768.00 MB
    Delta Memory :                               15175.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                305
    Run time :                                   14709 sec.
    Turnaround time :                            14265 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/automl_24639216.err> for stderr output of this job.

