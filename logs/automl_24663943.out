==========================================================
Job Started on n-62-20-6
Job ID: 24663943
Working Directory: /zhome/44/a/187127/school/Water-level-forecasting-new-project
Requested Cores: 4
Allocated Hosts: n-62-20-6 n-62-20-6 n-62-20-6 n-62-20-6
Queue: gpuv100
Start Time: Mon Apr 14 22:21:48 CEST 2025
==========================================================
Loading required modules...
Modules loaded:
Activating Conda environment 'forecasting'...
Conda environment: forecastinghpc
Python path: /zhome/44/a/187127/anaconda3/envs/forecastinghpc/bin/python
Working directory set to: /zhome/44/a/187127/school/Water-level-forecasting-new-project
Running automl.py...
2025-04-14 22:22:04.374188
sucess
                level  month  year  dayofyear  weekofyear
time                                                     
2014-06-20  11.437010      6  2014        171          25
2014-06-21  11.439094      6  2014        172          25
2014-06-22  11.435438      6  2014        173          25
2014-06-23  11.428292      6  2014        174          26
2014-06-24  11.427969      6  2014        175          26
running models:  ['linear_model', 'rf_model', 'xgb_model', 'fnn_model', 'rnn_model', 'cnn_model', 'rnnlstm_model', 'baseline_model']
error metric:  mse
                level  month  year  ...  mean_10_lag    lag_10d   lag_365d
time                                ...                                   
2015-06-20  11.448463      6  2015  ...    11.578021  11.555328  11.437010
2015-06-21  11.433109      6  2015  ...    11.575390  11.556492  11.439094
2015-06-22  11.435677      6  2015  ...    11.573720  11.568219  11.435438
2015-06-23  11.443779      6  2015  ...    11.568387  11.547730  11.428292
2015-06-24  11.430875      6  2015  ...    11.563143  11.544766  11.427969

[5 rows x 8 columns]
feature selection

Performing feature selection for linear_model
2025-04-14 22:22:04.449032
Tested feature 'month': Mean mse = 0.10083419761165568
Tested feature 'year': Mean mse = 0.13838220285430664
Tested feature 'dayofyear': Mean mse = 0.10197126105507254
Tested feature 'weekofyear': Mean mse = 0.1032023992929361
Tested feature 'mean_10_lag': Mean mse = 0.011355477834284552
Tested feature 'lag_10d': Mean mse = 0.01898741238247517
Tested feature 'lag_365d': Mean mse = 0.10699789969622649
Selected feature 'mean_10_lag' with improvement to mse = 0.011355477834284552
Tested feature 'month': Mean mse = 0.011333891339037694
Tested feature 'year': Mean mse = 0.011640548645519007
Tested feature 'dayofyear': Mean mse = 0.011332129570140152
Tested feature 'weekofyear': Mean mse = 0.011367719505651934
Tested feature 'lag_10d': Mean mse = 0.014609691332201672
Tested feature 'lag_365d': Mean mse = 0.012066785841088307
Selected feature 'dayofyear' with improvement to mse = 0.011332129570140152
Tested feature 'month': Mean mse = 0.011379116722836174
Tested feature 'year': Mean mse = 0.011646511845080797
Tested feature 'weekofyear': Mean mse = 0.011347038982210227
Tested feature 'lag_10d': Mean mse = 0.014585961376260302
Tested feature 'lag_365d': Mean mse = 0.01208564779112816
No further improvement, stopping feature selection.
Selected features for 'linear_model': ['mean_10_lag', 'dayofyear']

Performing feature selection for rf_model
2025-04-14 22:22:04.670182
Tested feature 'month': Mean mse = 0.07366312458439891
Tested feature 'year': Mean mse = 0.018107485718781968
Tested feature 'dayofyear': Mean mse = 0.08243023177796303
Tested feature 'weekofyear': Mean mse = 0.08301799685593181
Tested feature 'mean_10_lag': Mean mse = 0.023009711816639123
Tested feature 'lag_10d': Mean mse = 0.02891115093946769
Tested feature 'lag_365d': Mean mse = 0.10935909221839886
Selected feature 'year' with improvement to mse = 0.018107485718781968
Tested feature 'month': Mean mse = 0.009484853531592468
Tested feature 'dayofyear': Mean mse = 0.009394187475768544
Tested feature 'weekofyear': Mean mse = 0.00907579711163213
Tested feature 'mean_10_lag': Mean mse = 0.025490899952456476
Tested feature 'lag_10d': Mean mse = 0.006901636305318916
Tested feature 'lag_365d': Mean mse = 0.02515163684759523
Selected feature 'lag_10d' with improvement to mse = 0.006901636305318916
Tested feature 'month': Mean mse = 0.007219992090926985
Tested feature 'dayofyear': Mean mse = 0.007889912426198327
Tested feature 'weekofyear': Mean mse = 0.006075272865163572
Tested feature 'mean_10_lag': Mean mse = 0.008086141736726343
Tested feature 'lag_365d': Mean mse = 0.00762156459737285
Selected feature 'weekofyear' with improvement to mse = 0.006075272865163572
Tested feature 'month': Mean mse = 0.00601018452477545
Tested feature 'dayofyear': Mean mse = 0.007702391828928103
Tested feature 'mean_10_lag': Mean mse = 0.008512807576921464
Tested feature 'lag_365d': Mean mse = 0.006483220480847863
Selected feature 'month' with improvement to mse = 0.00601018452477545
Tested feature 'dayofyear': Mean mse = 0.008268389252273418
Tested feature 'mean_10_lag': Mean mse = 0.00874124312396673
Tested feature 'lag_365d': Mean mse = 0.006498813734232979
No further improvement, stopping feature selection.
Selected features for 'rf_model': ['year', 'lag_10d', 'weekofyear', 'month']

Performing feature selection for xgb_model
2025-04-14 22:22:51.183555
Tested feature 'month': Mean mse = 0.07379863512917265
Tested feature 'year': Mean mse = 0.01790376643749418
Tested feature 'dayofyear': Mean mse = 0.08233108328190324
Tested feature 'weekofyear': Mean mse = 0.08314756690370477
Tested feature 'mean_10_lag': Mean mse = 0.032815273807126656
Tested feature 'lag_10d': Mean mse = 0.03051705120830751
Tested feature 'lag_365d': Mean mse = 0.09448438451886347
Selected feature 'year' with improvement to mse = 0.01790376643749418
Tested feature 'month': Mean mse = 0.009643279595527183
Tested feature 'dayofyear': Mean mse = 0.011278135581531623
Tested feature 'weekofyear': Mean mse = 0.010680272253488268
Tested feature 'mean_10_lag': Mean mse = 0.02048339203910277
Tested feature 'lag_10d': Mean mse = 0.004854122107014996
Tested feature 'lag_365d': Mean mse = 0.03411627631734237
Selected feature 'lag_10d' with improvement to mse = 0.004854122107014996
Tested feature 'month': Mean mse = 0.00713207372908433
Tested feature 'dayofyear': Mean mse = 0.008607893840538748
Tested feature 'weekofyear': Mean mse = 0.0064896611732437074
Tested feature 'mean_10_lag': Mean mse = 0.006848975027895227
Tested feature 'lag_365d': Mean mse = 0.01164068336112019
No further improvement, stopping feature selection.
Selected features for 'xgb_model': ['year', 'lag_10d']

Performing feature selection for fnn_model
2025-04-14 22:22:53.342673
Tested feature 'month': Mean mse = 0.08814113749484613
Tested feature 'year': Mean mse = 0.24810417406129526
Tested feature 'dayofyear': Mean mse = 0.11436695441057032
Tested feature 'weekofyear': Mean mse = 0.07742136306858749
Tested feature 'mean_10_lag': Mean mse = 0.016153156648960772
Tested feature 'lag_10d': Mean mse = 0.01950451553763887
Tested feature 'lag_365d': Mean mse = 0.07681185939542663
Selected feature 'mean_10_lag' with improvement to mse = 0.016153156648960772
Tested feature 'month': Mean mse = 0.012931542926210014
Tested feature 'year': Mean mse = 0.09512967909676111
Tested feature 'dayofyear': Mean mse = 0.016683096135466462
Tested feature 'weekofyear': Mean mse = 0.018369343710918234
Tested feature 'lag_10d': Mean mse = 0.016632567201438762
Tested feature 'lag_365d': Mean mse = 0.01689840751807596
Selected feature 'month' with improvement to mse = 0.012931542926210014
Tested feature 'year': Mean mse = 0.04918868638075388
Tested feature 'dayofyear': Mean mse = 0.018271832702346627
Tested feature 'weekofyear': Mean mse = 0.02495567005511955
Tested feature 'lag_10d': Mean mse = 0.018629511472419577
Tested feature 'lag_365d': Mean mse = 0.015738060402283677
No further improvement, stopping feature selection.
Selected features for 'fnn_model': ['mean_10_lag', 'month']

Performing feature selection for rnn_model
2025-04-14 22:28:50.381258
Tested feature 'month': Mean mse = 0.09154352865114258
Tested feature 'year': Mean mse = 0.1004248305336158
Tested feature 'dayofyear': Mean mse = 1.489519174492754
Tested feature 'weekofyear': Mean mse = 0.07140771768264656
Tested feature 'mean_10_lag': Mean mse = 0.013191836265318968
Tested feature 'lag_10d': Mean mse = 0.01796806679797864
Tested feature 'lag_365d': Mean mse = 0.09912373851232002
Selected feature 'mean_10_lag' with improvement to mse = 0.013191836265318968
Tested feature 'month': Mean mse = 0.01192648894938099
Tested feature 'year': Mean mse = 0.11340663583114173
Tested feature 'dayofyear': Mean mse = 0.016987939807818025
Tested feature 'weekofyear': Mean mse = 0.02120344379697479
Tested feature 'lag_10d': Mean mse = 0.014978515442265012
Tested feature 'lag_365d': Mean mse = 0.016552513605828434
Selected feature 'month' with improvement to mse = 0.01192648894938099
Tested feature 'year': Mean mse = 0.19249632282034154
Tested feature 'dayofyear': Mean mse = 0.012427602650551086
Tested feature 'weekofyear': Mean mse = 0.01673379177816293
Tested feature 'lag_10d': Mean mse = 0.012339348291379058
Tested feature 'lag_365d': Mean mse = 0.01610029347419495
No further improvement, stopping feature selection.
Selected features for 'rnn_model': ['mean_10_lag', 'month']

Performing feature selection for cnn_model
2025-04-14 22:35:49.395206
Tested feature 'month': Mean mse = 0.07794357269556006
Tested feature 'year': Mean mse = 4.523577655472265
Tested feature 'dayofyear': Mean mse = 0.07632586108745008
Tested feature 'weekofyear': Mean mse = 0.076552563975687
Tested feature 'mean_10_lag': Mean mse = 0.018132969506854512
Tested feature 'lag_10d': Mean mse = 0.017191295164121132
Tested feature 'lag_365d': Mean mse = 0.10508810310051302
Selected feature 'lag_10d' with improvement to mse = 0.017191295164121132
Tested feature 'month': Mean mse = 0.023253231541318215
Tested feature 'year': Mean mse = 0.2591299597034846
Tested feature 'dayofyear': Mean mse = 0.02281221812106741
Tested feature 'weekofyear': Mean mse = 0.023554231060806823
Tested feature 'mean_10_lag': Mean mse = 0.019336739154108037
Tested feature 'lag_365d': Mean mse = 0.018802705797259855
No further improvement, stopping feature selection.
Selected features for 'cnn_model': ['lag_10d']

Performing feature selection for rnnlstm_model
2025-04-14 22:40:19.361101
Tested feature 'month': Mean mse = 0.1114376602226117
Tested feature 'year': Mean mse = 0.11953503460272703
Tested feature 'dayofyear': Mean mse = 0.10098760636185615
Tested feature 'weekofyear': Mean mse = 0.055479382128463865
Tested feature 'mean_10_lag': Mean mse = 0.047805175843907095
Tested feature 'lag_10d': Mean mse = 0.04576352854780399
Tested feature 'lag_365d': Mean mse = 0.08115587034371828
Selected feature 'lag_10d' with improvement to mse = 0.04576352854780399
Tested feature 'month': Mean mse = 0.040167329076700266
Tested feature 'year': Mean mse = 0.10399918531650258
Tested feature 'dayofyear': Mean mse = 0.028918941823777064
Tested feature 'weekofyear': Mean mse = 0.030685573586547294
Tested feature 'mean_10_lag': Mean mse = 0.03490874437477248
Tested feature 'lag_365d': Mean mse = 0.021768511022193886
Selected feature 'lag_365d' with improvement to mse = 0.021768511022193886
Tested feature 'month': Mean mse = 0.02182479716122115
Tested feature 'year': Mean mse = 0.09341623304818099
Tested feature 'dayofyear': Mean mse = 0.03695484120511644
Tested feature 'weekofyear': Mean mse = 0.027680366063405005
Tested feature 'mean_10_lag': Mean mse = 0.01501835560817445
Selected feature 'mean_10_lag' with improvement to mse = 0.01501835560817445
Tested feature 'month': Mean mse = 0.014961286091740203
Tested feature 'year': Mean mse = 0.07924462227957121
Tested feature 'dayofyear': Mean mse = 0.018755046889370477
Tested feature 'weekofyear': Mean mse = 0.02053409735931389
Selected feature 'month' with improvement to mse = 0.014961286091740203
Tested feature 'year': Mean mse = 0.16208824845116873
Tested feature 'dayofyear': Mean mse = 0.020421896934231767
Tested feature 'weekofyear': Mean mse = 0.021399340790985728
No further improvement, stopping feature selection.
Selected features for 'rnnlstm_model': ['lag_10d', 'lag_365d', 'mean_10_lag', 'month']

Performing feature selection for baseline_model
2025-04-14 22:51:14.159067
Univariate model selected. Using 'level' as the only feature for 'baseline_model'.

Starting hyperparameter tuning for 'linear_model'
2025-04-14 22:51:14.159105
Optimizing parameter group 'group1' for 'linear_model'
Tested params {'fit_intercept': True}: Mean mse = 0.011332129570140152
New best params for 'linear_model': {'fit_intercept': True} with Mean mse = 0.011332129570140152
Tested params {'fit_intercept': False}: Mean mse = 0.01446160028558855
Best parameters for 'linear_model': {'fit_intercept': True}
Best mean error for 'linear_model': 0.011332129570140152

Starting hyperparameter tuning for 'rf_model'
2025-04-14 22:51:14.184176
Optimizing parameter group 'group1' for 'rf_model'
Tested params {'max_depth': None, 'n_estimators': 25}: Mean mse = 0.006923337214293858
New best params for 'rf_model': {'max_depth': None, 'n_estimators': 25} with Mean mse = 0.006923337214293858
Tested params {'max_depth': None, 'n_estimators': 50}: Mean mse = 0.006237410178577734
New best params for 'rf_model': {'max_depth': None, 'n_estimators': 50} with Mean mse = 0.006237410178577734
Tested params {'max_depth': None, 'n_estimators': 100}: Mean mse = 0.006014902716817758
New best params for 'rf_model': {'max_depth': None, 'n_estimators': 100} with Mean mse = 0.006014902716817758
Tested params {'max_depth': None, 'n_estimators': 200}: Mean mse = 0.006225884932864093
Tested params {'max_depth': 5, 'n_estimators': 25}: Mean mse = 0.006178368907288006
Tested params {'max_depth': 5, 'n_estimators': 50}: Mean mse = 0.007098138255222138
Tested params {'max_depth': 5, 'n_estimators': 100}: Mean mse = 0.007376510621962613
Tested params {'max_depth': 5, 'n_estimators': 200}: Mean mse = 0.007405543006101752
Tested params {'max_depth': 10, 'n_estimators': 25}: Mean mse = 0.006544025575653878
Tested params {'max_depth': 10, 'n_estimators': 50}: Mean mse = 0.0060360760101339775
Tested params {'max_depth': 10, 'n_estimators': 100}: Mean mse = 0.00565307427419199
New best params for 'rf_model': {'max_depth': 10, 'n_estimators': 100} with Mean mse = 0.00565307427419199
Tested params {'max_depth': 10, 'n_estimators': 200}: Mean mse = 0.006251173174651489
Tested params {'max_depth': 20, 'n_estimators': 25}: Mean mse = 0.006756128749623982
Tested params {'max_depth': 20, 'n_estimators': 50}: Mean mse = 0.006592281675302121
Tested params {'max_depth': 20, 'n_estimators': 100}: Mean mse = 0.006212711600174369
Tested params {'max_depth': 20, 'n_estimators': 200}: Mean mse = 0.0061246402901800265
Tested params {'max_depth': 40, 'n_estimators': 25}: Mean mse = 0.005815580329728035
Tested params {'max_depth': 40, 'n_estimators': 50}: Mean mse = 0.006524888524030356
Tested params {'max_depth': 40, 'n_estimators': 100}: Mean mse = 0.00602172015937526
Tested params {'max_depth': 40, 'n_estimators': 200}: Mean mse = 0.005973260768896454
Optimizing parameter group 'group2' for 'rf_model'
Tested params {'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}: Mean mse = 0.008465459542336544
Tested params {'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5}: Mean mse = 0.007922781338446946
Tested params {'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2}: Mean mse = 0.00903939832367995
Tested params {'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5}: Mean mse = 0.008826835898803993
Tested params {'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 2}: Mean mse = 0.008159239603132857
Tested params {'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 5}: Mean mse = 0.00927446600159878
Tested params {'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2}: Mean mse = 0.007944816402684416
Tested params {'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5}: Mean mse = 0.007488392222692303
Tested params {'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 2}: Mean mse = 0.008765013241890626
Tested params {'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 5}: Mean mse = 0.008401318476642402
Tested params {'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 2}: Mean mse = 0.009889025254631508
Tested params {'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 5}: Mean mse = 0.009764020750392984
Tested params {'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2}: Mean mse = 0.005909384559436431
Tested params {'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 5}: Mean mse = 0.006788211007395672
Tested params {'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 2}: Mean mse = 0.006786155673411331
Tested params {'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 5}: Mean mse = 0.006778382433592777
Tested params {'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2}: Mean mse = 0.00709018755180271
Tested params {'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 5}: Mean mse = 0.007871912301449813
Best parameters for 'rf_model': {'max_depth': 10, 'n_estimators': 100}
Best mean error for 'rf_model': 0.00565307427419199

Starting hyperparameter tuning for 'xgb_model'
2025-04-14 22:52:07.588905
Optimizing parameter group 'group1' for 'xgb_model'
Tested params {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}: Mean mse = 0.004188442929030895
New best params for 'xgb_model': {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100} with Mean mse = 0.004188442929030895
Tested params {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}: Mean mse = 0.0042266644403793135
Tested params {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500}: Mean mse = 0.004487329116181397
Tested params {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}: Mean mse = 0.004314006110289121
Tested params {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}: Mean mse = 0.004382986839062548
Tested params {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 500}: Mean mse = 0.004540151082448379
Tested params {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}: Mean mse = 0.004705633318233484
Tested params {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}: Mean mse = 0.004741064524225143
Tested params {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}: Mean mse = 0.004912819912270842
Tested params {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}: Mean mse = 0.0043154233817548245
Tested params {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200}: Mean mse = 0.00421942081300395
Tested params {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 500}: Mean mse = 0.004335920024011321
Tested params {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}: Mean mse = 0.004235087296045139
Tested params {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200}: Mean mse = 0.004428521628457911
Tested params {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 500}: Mean mse = 0.004523321843867076
Tested params {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 100}: Mean mse = 0.004508108231408602
Tested params {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200}: Mean mse = 0.0046270955699276575
Tested params {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 500}: Mean mse = 0.00484109957641814
Tested params {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}: Mean mse = 0.023079005581474372
Tested params {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}: Mean mse = 0.007672462899286611
Tested params {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500}: Mean mse = 0.004387189189210799
Tested params {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100}: Mean mse = 0.021213164217597946
Tested params {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}: Mean mse = 0.006560050448398958
Tested params {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}: Mean mse = 0.004277247841884396
Tested params {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100}: Mean mse = 0.021213164217597946
Tested params {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200}: Mean mse = 0.006564035616317168
Tested params {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 500}: Mean mse = 0.0044929355571692925
Optimizing parameter group 'group2' for 'xgb_model'
Tested params {'gamma': 0, 'min_child_weight': 1}: Mean mse = 0.004188442929030895
Tested params {'gamma': 0, 'min_child_weight': 3}: Mean mse = 0.004111342674915506
New best params for 'xgb_model': {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'gamma': 0, 'min_child_weight': 3} with Mean mse = 0.004111342674915506
Tested params {'gamma': 0, 'min_child_weight': 5}: Mean mse = 0.004160549711834792
Tested params {'gamma': 0.2, 'min_child_weight': 1}: Mean mse = 0.008453238669910903
Tested params {'gamma': 0.2, 'min_child_weight': 3}: Mean mse = 0.008453238669910903
Tested params {'gamma': 0.2, 'min_child_weight': 5}: Mean mse = 0.008453238669910903
Optimizing parameter group 'group3' for 'xgb_model'
Tested params {'colsample_bytree': 0.6, 'subsample': 0.6}: Mean mse = 0.015096987462897206
Tested params {'colsample_bytree': 0.6, 'subsample': 1.0}: Mean mse = 0.01423334899522142
Tested params {'colsample_bytree': 1.0, 'subsample': 0.6}: Mean mse = 0.005011162792335333
Tested params {'colsample_bytree': 1.0, 'subsample': 1.0}: Mean mse = 0.004111342674915506
Optimizing parameter group 'group4' for 'xgb_model'
Tested params {'reg_alpha': 0, 'reg_lambda': 1}: Mean mse = 0.004111342674915506
Tested params {'reg_alpha': 0, 'reg_lambda': 1.5}: Mean mse = 0.004023901303387007
New best params for 'xgb_model': {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'gamma': 0, 'min_child_weight': 3, 'reg_alpha': 0, 'reg_lambda': 1.5} with Mean mse = 0.004023901303387007
Tested params {'reg_alpha': 1, 'reg_lambda': 1}: Mean mse = 0.005906023147360295
Tested params {'reg_alpha': 1, 'reg_lambda': 1.5}: Mean mse = 0.005744836613104628
Best parameters for 'xgb_model': {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'gamma': 0, 'min_child_weight': 3, 'reg_alpha': 0, 'reg_lambda': 1.5}
Best mean error for 'xgb_model': 0.004023901303387007

Starting hyperparameter tuning for 'fnn_model'
2025-04-14 22:52:16.113453
Optimizing parameter group 'group1_structure' for 'fnn_model'
Tested params {'units_layer1': 32, 'units_layer2': 16}: Mean mse = 0.016663615547694608
New best params for 'fnn_model': {'units_layer1': 32, 'units_layer2': 16} with Mean mse = 0.016663615547694608
Tested params {'units_layer1': 32, 'units_layer2': 32}: Mean mse = 0.016549924288840164
New best params for 'fnn_model': {'units_layer1': 32, 'units_layer2': 32} with Mean mse = 0.016549924288840164
Tested params {'units_layer1': 32, 'units_layer2': 64}: Mean mse = 0.01961742260664141
Tested params {'units_layer1': 64, 'units_layer2': 16}: Mean mse = 0.013834795324995555
New best params for 'fnn_model': {'units_layer1': 64, 'units_layer2': 16} with Mean mse = 0.013834795324995555
Tested params {'units_layer1': 64, 'units_layer2': 32}: Mean mse = 0.023550253265178903
Tested params {'units_layer1': 64, 'units_layer2': 64}: Mean mse = 0.01818596089826165
Tested params {'units_layer1': 128, 'units_layer2': 16}: Mean mse = 0.014183951179849939
Tested params {'units_layer1': 128, 'units_layer2': 32}: Mean mse = 0.016035481008674256
Tested params {'units_layer1': 128, 'units_layer2': 64}: Mean mse = 0.03016057987775866
Optimizing parameter group 'group2_activation' for 'fnn_model'
Tested params {'activation_layer1': 'relu', 'activation_layer2': 'relu'}: Mean mse = 0.014833190225580176
Tested params {'activation_layer1': 'relu', 'activation_layer2': 'tanh'}: Mean mse = 0.12545437819428643

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 24663943: <AutoML_WaterLevel> in cluster <dcc> Exited

Job <AutoML_WaterLevel> was submitted from host <hpclogin1> by user <s224296> in cluster <dcc> at Mon Apr 14 22:20:45 2025
Job was executed on host(s) <4*n-62-20-6>, in queue <gpuv100>, as user <s224296> in cluster <dcc> at Mon Apr 14 22:21:43 2025
</zhome/44/a/187127> was used as the home directory.
</zhome/44/a/187127/school/Water-level-forecasting-new-project> was used as the working directory.
Started at Mon Apr 14 22:21:43 2025
Terminated at Mon Apr 14 22:56:12 2025
Results reported at Mon Apr 14 22:56:12 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
# LSF Batch Job Script for running automl.py

### General LSF options ###

# -- Specify the queue --
# Use a GPU queue appropriate for your models (e.g., gpuv100 or gpua100)
# Remember A100 requires code compiled with CUDA >= 11.0
#BSUB -q gpuv100

# -- Set the job Name --
#BSUB -J AutoML_WaterLevel

# -- Ask for number of cores (CPU slots) --
# Adjust based on data loading/preprocessing needs. 8 is a reasonable start.
#BSUB -n 4

# -- Request GPU resources --
# Request 1 GPU in exclusive process mode.
#BSUB -gpu "num=1:mode=exclusive_process"

# -- Specify that all cores/GPU must be on the same host/node --
#BSUB -R "span[hosts=1]"

# -- Specify memory requested PER CORE/SLOT --
# Example: 8GB RAM per core (total 64GB). ADJUST BASED ON YOUR NEEDS!
#BSUB -R "rusage[mem=8GB]"

# -- Specify memory limit PER CORE/SLOT (Job killed if exceeded) --
# Example: 10GB per core (total 80GB limit). ADJUST BASED ON YOUR NEEDS!
#BSUB -M 9GB

# -- Set walltime limit: hh:mm --
# Max 24:00 for GPU queues. START SHORT (e.g., 1:00) FOR TESTING!
# Adjust based on expected runtime for the full job.
#BSUB -W 10:00

# -- Specify output and error files (%J expands to Job ID) --
# We'll create the 'logs' directory below.
#BSUB -o logs/automl_%J.out
#BSUB -e logs/automl_%J.err

# -- Email notifications (Optional) --
# Uncomment and set your DTU email if desired
##BSUB -u s224296@dtu.dk  # Use your actual email
# Send email on job start (-B) and job end/failure (-N)
##BSUB -B
##BSUB -N

### End of LSF options ###

(... more ...)
------------------------------------------------------------

Exited with exit code 143.

Resource usage summary:

    CPU time :                                   5.13 sec.
    Max Memory :                                 2651 MB
    Average Memory :                             2071.20 MB
    Total Requested Memory :                     32768.00 MB
    Delta Memory :                               30117.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                33
    Run time :                                   2069 sec.
    Turnaround time :                            2127 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/automl_24663943.err> for stderr output of this job.

